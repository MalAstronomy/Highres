{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mvasist/miniconda3/envs/HighResear/lib/python3.9/site-packages/petitRADTRANS/radtrans.py:113: FutureWarning: pRT_input_data_path was set by an environment variable. In a future update, the path to the petitRADTRANS input_data will be set within a .ini file that will be automatically generated into the user home directory (OS agnostic), inside a .petitradtrans directory\n",
      "  warnings.warn(f\"pRT_input_data_path was set by an environment variable. In a future update, the path to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Read line opacities of H2O_main_iso...\n",
      " Done.\n",
      "  Read line opacities of CO_main_iso...\n",
      " Done.\n",
      "  Read line opacities of CO_36...\n",
      " Done.\n",
      "\n",
      "  Read CIA opacities for H2-H2...\n",
      "  Read CIA opacities for H2-He...\n",
      "Done.\n",
      "\n",
      "  Read line opacities of H2O_main_iso...\n",
      " Done.\n",
      "  Read line opacities of CO_main_iso...\n",
      " Done.\n",
      "  Read line opacities of CO_36...\n",
      " Done.\n",
      "\n",
      "  Read CIA opacities for H2-H2...\n",
      "  Read CIA opacities for H2-He...\n",
      "Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as sched\n",
    "import wandb\n",
    "\n",
    "from dawgz import job, after, ensure, schedule\n",
    "from itertools import chain, islice\n",
    "from pathlib import Path\n",
    "from torch import Tensor\n",
    "Tensor\n",
    "from tqdm import tqdm\n",
    "from typing import *\n",
    "import pandas as pd\n",
    "\n",
    "from lampe.data import H5Dataset\n",
    "from zuko.distributions import BoxUniform\n",
    "from lampe.inference import NPE, NPELoss\n",
    "from lampe.nn import ResMLP\n",
    "from zuko.flows import NAF, NSF, MAF, NCSF, SOSPF, UNAF, CNF \n",
    "from lampe.plots import nice_rc, corner, coverage_plot, mark_point\n",
    "from lampe.utils import GDStep\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/mvasist/Highres/simulations/')\n",
    "from DataProcuring import Data \n",
    "from ProcessingSpec import ProcessSpec\n",
    "from parameter import *\n",
    "from spectra_simulator import SpectrumMaker\n",
    "from parameter_set_script import param_set, param_list, param_list_ext, param_set_ext, deNormVal\n",
    "# from spectra_simulator import Simulator, LOWER, UPPER\n",
    "# from AverageEstimator import avgestimator\n",
    "\n",
    "# sys.path.insert(0, '/home/mvasist/Highres/sbi/added_scripts/')\n",
    "from added_scripts.corner_modified import *\n",
    "from added_scripts.pt_plotting import *\n",
    "\n",
    "\n",
    "# from ees import Simulator, LOWER, UPPER, LABELS, pt_profile\n",
    "LABELS, LOWER, UPPER = zip(*[\n",
    "[                  r'$FeH$',  -1.5, 1.5],   # temp_node_9\n",
    "[                  r'$CO$',  0.1, 1.6],  # CO_mol_scale\n",
    "[                  r'$\\log g$',   2.5, 5.5],          # log g\n",
    "[                  r'$Tint$',  300,   3500],   # temp_node_5\n",
    "[                  r'$T1$',  300,   3500],      # T_bottom\n",
    "[                  r'$T2$',  300,   3500],   # temp_node_1\n",
    "[                  r'$T3$',  300,   3500],   # temp_node_2\n",
    "[                  r'$alpha$',  1.0, 2.0],   # temp_node_4\n",
    "[                  r'$log_delta$', 3.0, 8.0],   # temp_node_3\n",
    "[                  r'$log_Pquench$', -6.0, 3.0],   # temp_node_6\n",
    "[                  r'$logFe$',  -2.3, 1.0], # CH4_mol_scale\n",
    "[                  r'$fsed$',  0.0, 10.0],   # temp_node_8\n",
    "[                  r'$logKzz$',  5.0, 13.0], # H2O_mol_scale \\_mol\\_scale\n",
    "[                  r'$sigmalnorm$',  1.05, 3.0], # C2O_mol_scale\n",
    "[                  r'$log\\_iso\\_rat$',  -11.0, -1.0],   # temp_node_7\n",
    "[                  r'$R\\_P$', 0.8, 2.0],             # R_P / R_Jupyter\n",
    "[                  r'$rv$',  10.0, 30.0], # NH3_mol_scale 20, 35\n",
    "[                  r'$vsini$', 0.0, 50 ], # H2S_mol_scale 10.0, 30.0\n",
    "[                  r'$limb\\_dark$',  0.0, 1.0], # PH3_mol_scale\n",
    "[                  r'$b$',  1, 20.0], # PH3_mol_scale\n",
    "\n",
    "])\n",
    "\n",
    "scratch = os.environ['SCRATCH']\n",
    "datapath = Path(scratch) / 'highres-sbi/data_nic5'\n",
    "savepath = Path(scratch) / 'highres-sbi/runs/sweep_lognormnoise'\n",
    "\n",
    "processing = ProcessSpec()\n",
    "d = Data()\n",
    "sim = SpectrumMaker(wavelengths=d.model_wavelengths, param_set=param_set, lbl_opacity_sampling=2)\n",
    "\n",
    "\n",
    "def simulator(theta):\n",
    "    values = theta[:-4].numpy()\n",
    "    values_ext = theta[-4:].numpy()\n",
    "    # print(values, values_ext)\n",
    "    values_actual = deNormVal(values, param_list)\n",
    "    spectrum = sim(values_actual)\n",
    "    spec = np.vstack((np.array(spectrum), d.model_wavelengths))\n",
    "    \n",
    "    values_ext_actual = deNormVal(values_ext, param_list_ext)\n",
    "    # params_ext = param_set_ext.param_dict(values_ext_actual)\n",
    "    \n",
    "    th, x = processing(torch.Tensor([values_actual]), torch.Tensor(spec), sample= False, \\\n",
    "                       values_ext_actual= torch.Tensor([values_ext_actual]))\n",
    "    # print(np.shape(x))\n",
    "    return x.squeeze()\n",
    "\n",
    "\n",
    "## Loading from a model to plot\n",
    "CONFIGS = {\n",
    "    'embedding': ['shallow'],\n",
    "    'flow': ['MAF'],  #, 'NCSF', 'SOSPF', 'UNAF', 'CNF'], #'NAF', \n",
    "    'transforms': [3], #, 7], #3, \n",
    "    # 'signal': [16, 32],  # not important- the autoregression network output , 32\n",
    "    'hidden_features': [512], # hidden layers of the autoregression network , 256, \n",
    "    'hidden_features_no' : [5], \n",
    "    'activation': [nn.ELU], #, nn.ReLU],\n",
    "    'optimizer': ['AdamW'],\n",
    "    'init_lr':  [1e-3], #[5e-4, 1e-5]\n",
    "    'weight_decay': [1e-4], #[1e-4], #\n",
    "    'scheduler': ['ReduceLROnPlateau'], #, 'CosineAnnealingLR'],\n",
    "    'min_lr': [1e-5], # 1e-6\n",
    "    'patience': [16], #8\n",
    "    'epochs': [350],\n",
    "    'stop_criterion': ['early'], #, 'late'],\n",
    "    'batch_size':  [256],\n",
    "    'spectral_length' : [6144], #[1536, 3072, 6144]\n",
    "    'factor' : [0.3], \n",
    "    'noise_scaling' : [2], \n",
    "    'noise' : ['lognormaldist']\n",
    "    # 'SOSF_degree' : [2,3,4],\n",
    "    # 'SOSF_poly' : [2,4,6],\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_star =  torch.Tensor(np.loadtxt('/home/mvasist/Highres/observation/simulated_obs/x_sim_b.npy'))[0]\n",
    "theta_star = torch.Tensor(np.loadtxt('/home/mvasist/Highres/observation/simulated_obs/theta_sim_b.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6144]), torch.Size([19]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_star.size(), theta_star.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'cuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 129\u001b[0m\n\u001b[1;32m    123\u001b[0m     mark_point(corner_fig, thetascalebackup(theta_star), color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    124\u001b[0m     corner_fig\u001b[38;5;241m.\u001b[39msavefig(savepath_plots \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorner.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 129\u001b[0m \u001b[43mexperiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 101\u001b[0m, in \u001b[0;36mexperiment\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# #     ## Corner\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     theta_star \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(np\u001b[38;5;241m.\u001b[39mloadtxt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/mvasist/Highres/observation/simulated_obs/theta_sim_b.npy\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m--> 101\u001b[0m     x_star \u001b[38;5;241m=\u001b[39m  \u001b[43mnoisy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/mvasist/Highres/observation/simulated_obs/x_sim_b.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m()\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    104\u001b[0m         theta \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([estimator\u001b[38;5;241m.\u001b[39mflow(x_star\u001b[38;5;241m.\u001b[39mcuda())\u001b[38;5;241m.\u001b[39msample((\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m,))\u001b[38;5;241m.\u001b[39mcpu() \u001b[38;5;66;03m#**14\u001b[39;00m\n\u001b[1;32m    105\u001b[0m                             \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m    106\u001b[0m             \n\u001b[1;32m    107\u001b[0m                     ])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'cuda'"
     ]
    }
   ],
   "source": [
    "def experiment(): #index: int) -> None:\n",
    "    # Config\n",
    "    config = {\n",
    "        key: random.choice(values)\n",
    "        for key, values in CONFIGS.items()\n",
    "    }\n",
    "        \n",
    "    def noisy(x, b= None): #50 is 10% of the median of the means of spectra in the training set.\n",
    "        bs = x.size()[0]\n",
    "        data_uncertainty = Data().err * Data().flux_scaling\n",
    "\n",
    "        if b == None: \n",
    "            if config['noise'] == 'uniformdist' :\n",
    "                b = 1  + torch.rand(bs) * (10-1)\n",
    "                b = torch.unsqueeze(b,1)\n",
    "            elif config['noise'] == 'lognormaldist' :\n",
    "                m = torch.distributions.log_normal.LogNormal(torch.tensor([1.5]), torch.tensor([0.5]))\n",
    "                b = m.sample([bs])\n",
    "            # elif config['noise'] == 'Mikelineb' :\n",
    "            #     data_uncertainty = noisybfactor(x) \n",
    "\n",
    "        else: \n",
    "            b = torch.Tensor([b])\n",
    "        \n",
    "        # print(b.size(), torch.from_numpy(data_uncertainty).size(), torch.randn_like(x).size())\n",
    "        x = x + torch.from_numpy(data_uncertainty).cuda() * b.cuda() * torch.randn_like(x) \n",
    "        \n",
    "        return x, b\n",
    "\n",
    "\n",
    "    class NPEWithEmbedding(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "            # Estimator\n",
    "            if config['embedding'] == 'shallow':\n",
    "                self.embedding = ResMLP(6144, 64, hidden_features=[512] * 2 + [256] * 3 + [128] * 5, activation= nn.ELU)\n",
    "            else:\n",
    "                self.embedding = ResMLP(6144, 128, hidden_features=[512] * 3 + [256] * 5 + [128] * 7, activation= nn.ELU)\n",
    "\n",
    "            if config['flow'] == 'MAF':\n",
    "                self.npe = NPE(\n",
    "                    20, self.embedding.out_features,\n",
    "                    # moments=((l + u) / 2, (l - u) / 2),\n",
    "                    transforms=config['transforms'],\n",
    "                    build=MAF,\n",
    "                    # bins=config['signal'],\n",
    "                    hidden_features=[config['hidden_features']] * config['hidden_features_no'],\n",
    "                    activation=config['activation'],\n",
    "                )\n",
    "\n",
    "        def forward(self, theta, x): # -> Tensor:\n",
    "            y = self.embedding(x)\n",
    "            return self.npe(theta, y)\n",
    "\n",
    "        # def flow(self, x: Tensor):  # -> Distribution\n",
    "        def flow(self, x):  # -> Distribution\n",
    "            out = self.npe.flow(self.embedding(x)) #.to(torch.double)) #\n",
    "            return out\n",
    "    \n",
    "    estimator = NPEWithEmbedding().double().cuda()\n",
    "\n",
    "    def pipeout(theta: Tensor, x: Tensor) -> Tensor:\n",
    "        theta, x = theta.cuda(), x.cuda()\n",
    "        x , b = noisy(x)\n",
    "        theta = torch.hstack((theta, b.cuda()))\n",
    "        return theta, x\n",
    "\n",
    "############################################################\n",
    "    # datapath = Path(scratch) / 'highres-sbi/data_nic5'\n",
    "    # savepath = Path(scratch) / 'highres-sbi/runs/sweep_lessnoisy'\n",
    "    # Loading from a model to plot\n",
    "    m = 'peachy-feather-81' #'comfy-dawn-59'\n",
    "    epoch = config['epochs']\n",
    "    runpath = savepath / m\n",
    "    runpath.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    estimator = NPEWithEmbedding().double()\n",
    "    states = torch.load(runpath / ('states_' + str(epoch) + '.pth'), map_location='cpu')\n",
    "    estimator.load_state_dict(states['estimator'])\n",
    "    estimator.cuda().eval()\n",
    "\n",
    "############################################################\n",
    "        \n",
    "    savepath_plots = runpath  / ('plots_sim_b_' + str(epoch))\n",
    "    savepath_plots.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "####################################################################################################################\n",
    "    # Evaluation\n",
    "    plt.rcParams.update(nice_rc(latex=True))\n",
    "\n",
    "# ####################################################################################################\n",
    "\n",
    "    def thetascalebackup(theta):\n",
    "         #almost same as deNormVal(outputs a list not tensor)\n",
    "        theta[:, :-1] =  torch.Tensor(LOWER[:-1]) + theta[:, :-1] * (torch.Tensor(UPPER[:-1]) - torch.Tensor(LOWER[:-1]))\n",
    "        return theta\n",
    "\n",
    "# #     ## Corner\n",
    "    theta_star = torch.Tensor(np.loadtxt('/home/mvasist/Highres/observation/simulated_obs/theta_sim_b.npy'))\n",
    "    x_star =  noisy(torch.Tensor(np.loadtxt('/home/mvasist/Highres/observation/simulated_obs/x_sim_b.npy')).cuda()[0])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        theta = torch.cat([estimator.flow(x_star.cuda()).sample((2**3,)).cpu() #**14\n",
    "                            for _ in tqdm(range(2**6))\n",
    "            \n",
    "                    ])\n",
    "\n",
    "#     ##Saving to file\n",
    "    theta_numpy = theta.double().numpy() #convert to Numpy array\n",
    "    df_theta = pd.DataFrame(theta_numpy) #convert to a dataframe\n",
    "    df_theta.to_csv( savepath_plots / 'theta.csv' ,index=False) #save to file\n",
    "    \n",
    "    #Then, to reload:\n",
    "    df_theta = pd.read_csv( savepath_plots / 'theta.csv')\n",
    "    theta = df_theta.values\n",
    "    theta = torch.from_numpy(theta)\n",
    "    # print(theta)\n",
    "    \n",
    "    corner_fig = corner_mod([thetascalebackup(theta)], legend=['NPE'], \\\n",
    "                    color= ['steelblue'] , figsize=(19,19), \\\n",
    "                 domain = (LOWER, UPPER), labels= LABELS) #\n",
    "    mark_point(corner_fig, thetascalebackup(theta_star), color='black')\n",
    "    corner_fig.savefig(savepath_plots / 'corner.pdf')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     ####################################################################################################\n",
    "# #     ## NumPy\n",
    "#     def filter_limbdark_mask(theta):\n",
    "#         mask = theta[:,-2]<0\n",
    "#         mask += theta[:,-2]>1\n",
    "#         return mask \n",
    "\n",
    "#     # print(thetascalebackup(theta))\n",
    "#     mask = filter_limbdark_mask(thetascalebackup(theta))\n",
    "#     theta_filterLD = theta[~mask]\n",
    "#     # print(theta_filterLD)\n",
    "\n",
    "\n",
    "# ### PT profile\n",
    "#     fig, ax = plt.subplots(figsize=(4,4))\n",
    "\n",
    "#     ##sim PT\n",
    "#     pressures = sim.atmosphere.press / 1e6\n",
    "#     val_act = deNormVal(theta_star.numpy(), param_list)\n",
    "#     params = param_set.param_dict(val_act)\n",
    "#     temp= make_pt(params , pressures)\n",
    "#     ax.plot(temp, pressures, color = 'black')  ##sim\n",
    "#     ##sim PT\n",
    "    \n",
    "#     fig_pt = PT_plot(fig, ax, theta_filterLD[:2**8, :-1], invert = True) #, self.theta_star)\n",
    "#     # fig_pt = PT_plot(fig_pt, ax, self.theta_paul[:2**8], invert = True, color = 'orange') #, theta_star)\n",
    "#     # fig_pt.savefig(self.savepath_plots / 'pt_profile_Paul_unregPTwithb_24Apr2023.pdf')\n",
    "#     fig_pt.savefig(savepath_plots / 'pt_profile.pdf')\n",
    "\n",
    "# ####################################################################################################\n",
    "\n",
    "#     # ## Residuals\n",
    "#     theta_filterLD_512 = theta_filterLD[:2**9]\n",
    "#     x_filterLD_512 = np.stack([simulator(t) for t in tqdm(theta_filterLD_512[:,:-1])]) #**9\n",
    "#     x_filterLD_512 = x_filterLD_512[:,0]\n",
    "#     mask = ~np.isnan(x_filterLD_512).any(axis=-1)\n",
    "#     mask1 = ~np.isinf(x_filterLD_512[mask]).any(axis=-1)\n",
    "#     theta_filterLD_512, x_filterLD_512 = theta_filterLD_512[mask][mask1], x_filterLD_512[mask][mask1]\n",
    "#     x_filterLD_512 = torch.from_numpy(x_filterLD_512)\n",
    "#     x_filterLD_512, _= noisy(x_filterLD_512.cuda(), theta_filterLD_512[:, -1])\n",
    "#     # x_filterLD_512, _= noisy(x_filterLD_512.cuda(), theta_filterLD_512[:, -1])\n",
    "\n",
    "#     df_theta = pd.DataFrame(theta_filterLD_512) #convert to a dataframe\n",
    "#     df_x = pd.DataFrame(x_filterLD_512.cpu()) #convert to a dataframe\n",
    "\n",
    "#     df_theta.to_csv('theta_256_noisy.csv',index=False) #save to file\n",
    "#     df_x.to_csv('x_256_noisy.csv',index=False) #save to file\n",
    "\n",
    "#     #Then, to reload:\n",
    "#     df_theta = pd.read_csv('theta_256_noisy.csv')\n",
    "#     theta_256_noisy = df_theta.values\n",
    "#     df_x = pd.read_csv('x_256_noisy.csv')\n",
    "#     x = df_x.values\n",
    "#     theta_256_noisy, x_256_noisy = torch.from_numpy(theta_256_noisy), torch.from_numpy(x)\n",
    "\n",
    "#     res_fig, (ax1, ax2) = plt.subplots(2, figsize=(10,7), gridspec_kw={'height_ratios': [3, 1]})\n",
    "#     creds= [0.997, 0.955, 0.683]\n",
    "#     alpha = (0.0, 0.9)\n",
    "#     levels, creds = levels_and_creds(creds= creds, alpha = alpha)\n",
    "#     cmap= LinearAlphaColormap('steelblue', levels=creds, alpha=alpha)\n",
    "\n",
    "#     wlength = d.data_wavelengths\n",
    "\n",
    "#     for q, l in zip(creds[:-1], levels):\n",
    "#         lower, upper = np.quantile(x_256_noisy.numpy(), [0.5 - q / 2, 0.5 + q / 2], axis=0)\n",
    "#         ax1.fill_between(wlength, lower, upper, color= cmap(l), linewidth=0) #'C0', alpha=0.4,\n",
    "\n",
    "#     lines = ax1.plot(wlength, x_star.cpu(), color='black', label = r'$ f(\\theta_{obs})$', linewidth = 0.4)\n",
    "#     handles, texts = legends(axes= ax1, alpha=alpha) #0.15, 0.75\n",
    "#     texts = [r'$ f(\\theta_{obs})$', r'$p_{\\phi}(f(\\theta)|x_{obs})$']\n",
    "\n",
    "#     plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "#     ax1.set_ylabel(r'Planet flux $F_\\nu$ (10$^{-5}$) Jy', fontsize = 10)\n",
    "#     ax1.legend(handles, texts, prop = {'size': 8}, bbox_to_anchor=(1,1))\n",
    "\n",
    "#     residuals = (x_256_noisy - x_star.cpu()) / torch.Tensor(d.err*d.flux_scaling*config['noise_scaling'])\n",
    "\n",
    "#     for q, l in zip(creds[:-1], levels):\n",
    "#         lower, upper = np.quantile(residuals, [0.5 - q / 2, 0.5 + q / 2], axis=0)\n",
    "#         ax2.fill_between(wlength, lower, upper, color= cmap(l) , linewidth=0) \n",
    "#     ax2.set_ylabel(r'Residuals', fontsize = 10)\n",
    "#     ax2.set_xlabel( r'Wavelength ($\\mu$m)', fontsize = 10)\n",
    "#     res_fig.savefig(savepath_plots / 'consistency_noisy.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:HighResear]",
   "language": "python",
   "name": "conda-env-HighResear-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
